{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Bagging and Hyperparameter tuning  \n",
    "\n",
    "<img src=\"./images/bags.jpg\" alt=\"The bagging operation\" width=\"400\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Spam vs. not-Spam Dataset\n",
    "<img src=\"./images/spam_or_not_spam.png\" alt=\"Spam vs. not-Spam\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the (Spam vs. not-Spam) dataset:\n",
    "* The dataset tags email messages as spam or not-spam.\n",
    "* Classes (=categories): there are two possible classes: not_spam, spam\n",
    "* Attributes (=features): there are 57 features, including two types of features:\n",
    "  * word frequencies - the feature name contains a word, with the suffix '_wordFreq' e.g.: 'make_wordFreq'  \n",
    "    * The word could appear 0 times in a specific email, once or a few times.\n",
    "    * The values of this feature could be between 0 and 1 (the frequency is relative).\n",
    "  * Capital Letter pattern attributes - 3 features regarding capital letter patterns. e.g.: 'capitalLet_long' - the length of the longest sequence of capital letters in the email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The assignment has to do with the (Spam vs. not-Spam) dataset\n",
    "* This assignment is a bigger assignment and is graded accordingly (20 points total)\n",
    "  * It includes different methods to implement, related to the Bagging algorithm \n",
    "* At the end of the assignment, there is an optional bonus method to implement (additional 5 points)\n",
    "  * It also includes an , regarding hyperparameters tunig \n",
    "* Note: the maximum possible points for all the assignments together are - 70 points \n",
    "  * The extra 30 points come from the test\n",
    "* Note: previous assignments and class exercises, could assist you with similar materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General instructions:\n",
    "Please Read the following instructions, and make sure you follow all steps, before submiting your assignment via moodle:\n",
    "- Put your code one line after the '# YOUR CODE HERE' remark\n",
    "- You must remove the 'raise NotImplementedError()' exception raising line (which appears a line after the above remark).\n",
    "    * if you do not remove this line, it will be a sign that you didn't implement that code, and we won't be able to check your work\n",
    "- Do NOT remove any other line in this notebook    \n",
    "- you also need to implement the two functions 'myName', 'myId'\n",
    "    * myName - you need to return your full name as a string\n",
    "    * myId - you need to return your ID number as a an integer    \n",
    "- When you want to check your work, select the 'Cell' --> 'Run All' menu\n",
    "    * before performing your filnal test, we suggest to clear previous output (by selecting 'Cell' --> 'All output' --> 'Clear' menu) and then reperform the final execution ('Cell' --> 'Run All') of the code.\n",
    "    * after performing 'Run All', make sure there are no exceptions thrown and that the output is as you expected.\n",
    "- Don't forget to save your work, by clicking the 'save' icon (in the upper left part of the screen), or by selecting the 'File' --> 'Save and checkpoint' menu item. \n",
    "- Do NOT change the file name of this notebook\n",
    "- The work is done individualy, for each student\n",
    "- Each student needs to submit his/her assignment through moodle.\n",
    "- Submit the python notebook only (not any additional possible files) \n",
    "<br/><br/>\n",
    "Good Luck :-)<br/>\n",
    "The courses staff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Student information methods:\n",
    "The following 2 cells consist of 2 methods which aim to validate your details.<br/>\n",
    "Please <b>make sure to implement <u>both</u> of them</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9b37d2297534714fc0f385d860f6b2f",
     "grade": false,
     "grade_id": "myName-Method",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return your full name (as a string)\n",
    "# example: assume your name is John Smith:\n",
    "# return 'John Smith'\n",
    "# ------------\n",
    "# return value:\n",
    "# - your full name (as a string)\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "def myName():\n",
    "    # ADD the return statement in the LINE AFTER: '# YOUR CODE HERE'\n",
    "    # REMOVE THE LINE: raise NotImplementedError()\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf205f4550ee70f47db218c42b267bc7",
     "grade": false,
     "grade_id": "myIdMethod",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return your ID number (as an integer number)\n",
    "# example: assume your ID number is 1234:\n",
    "# return 1234 \n",
    "# ------------\n",
    "# return value:\n",
    "# - your ID number (as an integer number)\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "def myId():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "642e7f88f2c9d55f275d1af8bb64de02",
     "grade": false,
     "grade_id": "cell-c64165dd6b6c2ded",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests \n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "## 'myName' and 'myId' implementation methods\n",
    "# It tests the correctness their implementation\n",
    "# Important Note: additional test might also be taken from our side.\n",
    "# --------------------------------------------------------\n",
    "aName = myName()\n",
    "aId = myId()\n",
    "assert aName is not None, 'no return student name'\n",
    "assert type(aName) is str, \"name is not a string: %r\" % aName\n",
    "print (\"'myName' method validation is successfull!\")\n",
    "print (\"your name is: %s\" %(aName))\n",
    "print (\"--------------------------------------\")\n",
    "assert aId is not None, 'no return student id'\n",
    "assert type(aId) is int, \"id is not an integer: %r\" % aId\n",
    "print (\"'myId' method validation is successfull!\")\n",
    "print (\"your id is: %d\" %(aId))\n",
    "## END OF 'myName' and 'myId' implementation validation\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Loading dataset - maximum possible points: 3\n",
    "The following cells perform 5 things:\n",
    "* Preceding step - import packages\n",
    "* step 1 - load the 'spam vs not-spam' dataset ----> Student's implementation - total 1 point\n",
    "* step 2 - split dataframe to X (feature vectors) and y (classes) ----> Student's implementation - total 1 point \n",
    "* step 3 - change classes values from string to number ----> Student's implementation - total 1 point \n",
    "* step 4 - split the dataset to a train-set and a test-set ----> run only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preceding Step - import packages\n",
    "This step is necessary in order to use external packages. <br/><br/>\n",
    "<u>Some of the exteranl packages include</u>: \n",
    "* pandas - which we use mainly for dataframes and series\n",
    "* numpy - which we use for advance operations, such as unique values of arrays\n",
    "* random - which we could use to select random value (like we studied in earlier exercises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPORT (PACKAGES) CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# - Do NOT change or delete the following imports:\n",
    "import sys\n",
    "import os\n",
    "import pathlib \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Note: do NOT add imports, such as sklearn, which could\n",
    "# answer the following questions.\n",
    "# --- add your imports here IF NEEDED:\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - step 1 - load the 'spam vs not-spam' dataset ----> Student's implementation - total 1 point\n",
    "<img src=\"./images/load_dataframe.jpg\" alt=\"load dataframe\" width=\"100\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f07989e1ef8949fd5becf91a79420b42",
     "grade": false,
     "grade_id": "loading_dataframe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: loadDataset \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return the dataset from the input csv file.\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - 'fileName' - full path of the csv fileName \n",
    "# ------------\n",
    "# return value:\n",
    "# - a dataframe structure containing the dataset\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------- \n",
    "def loadDataset(fileName):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "225e1d0bb699bf40dfd1ca1e36a7f631",
     "grade": true,
     "grade_id": "loading_dataframe_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'loadDataset' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "print (\"Testing your implementation of the 'loadDataset' method ...\")\n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "assert dataset_forTesting is not None, 'spam_notSpam object not initialized'\n",
    "assert isinstance(dataset_forTesting, pd.DataFrame), 'spam_notSpam object is not a dataframe'\n",
    "assert dataset_forTesting.empty == False, 'spam_notSpam dataframe object is empty'\n",
    "assert len(dataset_forTesting.columns)==58, 'spam_notSpam dataframe object is missing columns'\n",
    "assert len(dataset_forTesting.index)==4601, 'spam_notSpam dataframe object is missing rows'\n",
    "print (\"----> The 'spam vs not-spam' dataframe object was loaded successfuly :-) \\n\")\n",
    "dataset_forTesting=None\n",
    "print ('The beginning (the head) of the dataframe:')\n",
    "print ('\\nNote: Additional Tests might be executed on our side')\n",
    "loadDataset(datasetCsvFileName).head()\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - step 2 - split dataframe to X (feature vectors) and y (classes) ----> Student's implementation - total 1 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "608d1ec6e8e9b31853108e36025a661b",
     "grade": false,
     "grade_id": "seperate_to_x_and_y",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: separateTo_X_and_y \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# ---- The method should separate the input dataset into two parts:\n",
    "# 1. X (feature vectors)  \n",
    "# 2. y (categories) \n",
    "# ------------\n",
    "# input parameters:\n",
    "# - dataset -  a dataframe structure, containing the dataset.\n",
    "# - classColName - the column name (string) containing the categories\n",
    "# ------------\n",
    "# return values (comma separated):\n",
    "# - X_featureVectores - a dataframe containing all feature vectors. \n",
    "#                       It should contain the input dataframe after removing the class column.\n",
    "#                       The index of the X_featureVectores should be the same as the input dataframe parameter.\n",
    "# - y_Categories      - a series of containing all class values per instance.\n",
    "#                       The index of the y_Categories series should be the same as the input dataframe.\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------- \n",
    "def separateTo_X_and_y(dataset, classColName):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f8d4b2ae02953a94931be97a37884b9",
     "grade": true,
     "grade_id": "separateTo_X_and_y-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'separateTo_X_and_y' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "print (\"Testing your implementation of the 'separateTo_X_and_y' method ...\")\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "# ---------------------\n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "assert X_vectors is not None, 'X_vectors object not initialized'\n",
    "assert isinstance(X_vectors, pd.DataFrame), 'X_vectors object is not a dataframe'\n",
    "assert X_vectors.empty == False, 'X_vectors dataframe object is empty'\n",
    "assert sameIndexes(X_vectors,dataset_forTesting), 'X_vectors should share the same indexes as the dataset'\n",
    "assert y_categories is not None, 'y_categories object not initialized'\n",
    "assert isinstance(y_categories, pd.Series), 'y_categories object is not a series'\n",
    "assert y_categories.empty == False, 'y_categories dataframe object is empty'\n",
    "assert sameIndexes(X_vectors,y_categories), 'X_vectors should share the same indexes as y_categories'\n",
    "print (\"----> The 'separateTo_X_and_y' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "# --------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - step 3 - change classes values from string to number ----> Student's implementation - total 1 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cab0a3ea6e38c47951e19e986ebfd31",
     "grade": false,
     "grade_id": "categories-to-nums",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: separateTo_X_and_y \n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# ---- The method changes the input string categories to int categories.\n",
    "#      'not_spam' --> 0\n",
    "#      'spam'     --> 1\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - y_Categories -  a dataframe structure, containing the dataset.\n",
    "# - positiveClassName - the name of the category (string) of the positive class\n",
    "#                       * if the value of a cell does not equal positiveClassName, \n",
    "#                         it should be considered as negative.\n",
    "# ------------\n",
    "# return value: \n",
    "# - y_NumCategories - a series of containing all class values with numeric values per instance.\n",
    "#                       * each cell value, which equals the negativeClassName will recieve a value of 0 in the\n",
    "#                         output series.\n",
    "#                       * each cell value, which equals the positiveClassName will recieve a value of 1 in the\n",
    "#                         output series.\n",
    "#                       * the index should be the same of the input series.\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------- \n",
    "def datasetCategoriesToNums(y_Categories, positiveClassName):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5cfbb886fb0ec632fe235d25755e20f",
     "grade": true,
     "grade_id": "categories-to-nums-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'datasetCategoriesToNums' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "print (\"Testing your implementation of the 'datasetCategoriesToNums' method ...\")\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categoriesB4 = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categoriesB4, 'spam')\n",
    "# --------------------- \n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "assert y_categories is not None, 'y_categories object not initialized'\n",
    "assert isinstance(y_categories, pd.Series), 'y_categories object is not a series'\n",
    "assert y_categories.empty == False, 'y_categories dataframe object is empty'\n",
    "assert sameIndexes(y_categories,y_categoriesB4), 'y_categories should share the same indexes as y_categoriesB4'\n",
    "assert allValidVals(np.unique(y_categories.values),(0,1)), 'classes should be only 0 or 1 (as an integer number)'\n",
    "print (\"----> The 'datasetCategoriesToNums' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - step 4 - split the dataset to a train-set and a test-set ----> run only\n",
    "<img src=\"./images/train-test-split.png\" alt=\"train-test split\" width=\"100\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1ba142a8eb56c7d0c893905794f37fe",
     "grade": false,
     "grade_id": "train-test-split",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name1: trainTestSplit\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- the method split the input dataset into train and test. \n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_vectors - a dataframe containing all feature vectors. \n",
    "# - y_categories - a series of containing all class values per instance.\n",
    "# - test_size_ratio - a number (0<number<1) of the wanted ratio of the dataset out of the dataset \n",
    "# - rand_state - a number, in order to guarantee reproducible results \n",
    "# ------------\n",
    "# return values (comma separated):\n",
    "# - X_train -  a dataframe containing all feature vectors of the train set\n",
    "# - X_test -  a dataframe containing all feature vectors of the test set\n",
    "# - y_train - a series of containing all class values per train instance\n",
    "# - y_test - a series of containing all class values per test instance\n",
    "# --------------------- \n",
    "def trainTestSplit(X_vectors, y_categories, test_size_ratio, rand_state):\n",
    "    return train_test_split(X_vectors, y_categories, test_size=test_size_ratio, random_state=rand_state)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name2: reAttachTrainSet\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- the method split the input dataset into train and test. \n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_train -  a dataframe containing all feature vectors of the train set\n",
    "# - y_train - a series of containing all class values per train instance\n",
    "# ------------\n",
    "# return value:\n",
    "# - train_set - a reattached dataframe, consisting both feature vectors and categories.\n",
    "# --------------------- \n",
    "def reAttachTrainSet(X_train, y_train):\n",
    "    return pd.concat((X_train, y_train), axis=1)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 25)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# display train-test split information\n",
    "# --------------------------------------------------------\n",
    "print ('Information after train-test split:')\n",
    "print('The train-set includes %d instances and %d corresponding categories\\n' %(X_train.shape[0],y_train.shape[0]))\n",
    "print('The test-set includes %d instances and %d corresponding categories\\n' %(X_test.shape[0],y_test.shape[0]))\n",
    "\n",
    "# --------------------------------------------------------\n",
    "## concatinate the X_train and y_train:\n",
    "# --------------------------------------------------------\n",
    "train_set = reAttachTrainSet(X_train, y_train)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Display the first few rows of the training-set:\n",
    "# --------------------------------------------------------\n",
    "print('First few rows of unified train-set:')\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Building a Bagging Classifier\n",
    "<img src=\"./images/bagging-classifier.jpeg\" alt=\"bagging-classifier\" width=\"400\" align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3a - Bootstrap - maximum possible points: 8\n",
    "The following cells perform 2 methods:\n",
    "* step 1 - instance bootstrap ----> Student's implementation - total 4 point\n",
    "* step 2 - feature bootstrap ----> Student's implementation - total 4 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3a - step 1 - instance bootstrap ----> Student's implementation - total 4 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "678eca7748390713d38eb195317297f1",
     "grade": false,
     "grade_id": "instance-bootstrap",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 4\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: instanceBootStrap\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- the method samples the dataset uniformly with replacements. \n",
    "#     * this means that there is a chance we could get the same instance more than once\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_train - a dataframe containing all training feature vectors. \n",
    "# - y_train - a series of containing all training class values per instance.\n",
    "# - sampleRatio - the ratio of the sampeling out of training set \n",
    "#               * we will derive the number of instances to sample from sampleRatio\n",
    "# ------------\n",
    "# return values (comma separated):\n",
    "# - X_trainSampled - a dataframe containing sampled training feature vectors. \n",
    "# - y_trainSampled - a series of containing Sampled training class values per instance.\n",
    "# Note: X_trainSampled should have the same index as y_trainSampled \n",
    "# --------------------- \n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------- \n",
    "def instanceBootStrap(X_train, y_train, sampleRatio):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d54b3e84c17d4bdfae8130c8e59a5cb8",
     "grade": true,
     "grade_id": "instance-nootStrap-test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 4\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'instanceBootStrap' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------------------------------------------\n",
    "print (\"Testing your implementation of the 'instanceBootStrap' method ...\")\n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 35)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "X_train_100 = X_train.iloc[:100,:]\n",
    "y_train_100 = y_train.iloc[:100]\n",
    "sampleRatio = 0.5\n",
    "X_trainSampled, y_trainSampled = instanceBootStrap(X_train_100, y_train_100, sampleRatio)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "assert X_trainSampled is not None, 'X_trainSampled object not initialized'\n",
    "assert isinstance(X_trainSampled, pd.DataFrame), 'X_trainSampled object is not a dataframe'\n",
    "assert X_trainSampled.empty == False, 'X_trainSampled dataframe object is empty'\n",
    "assert y_trainSampled is not None, 'y_trainSampled object not initialized'\n",
    "assert isinstance(y_trainSampled, pd.Series), 'y_trainSampled object is not a series'\n",
    "assert y_trainSampled.empty == False, 'y_trainSampled series object is empty'\n",
    "assert sameIndexes(X_trainSampled,y_trainSampled), 'X_trainSampled should share the same indexes as y_trainSampled'\n",
    "assert allValidVals(np.unique(y_categories.values),(0,1)), \"y_trainSampled's value should be only 0 or 1 (as an integer number)\"\n",
    "print (\"----> The 'instanceBootStrap' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "X_train_100 = None\n",
    "y_train_100 = None\n",
    "sampleRatio = None\n",
    "X_trainSampled = None\n",
    "y_trainSampled = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3a - step 2 - feature bootstrap ----> Student's implementation - total 4 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "948f9ad2e06f5c6a52bfbee12f378fee",
     "grade": false,
     "grade_id": "feature-bootstrap",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 4\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: featureBootStrap\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- the method samples the featureset uniformly with replacements. \n",
    "#     * this means that there is a chance we could choose the same feature twice \n",
    "#     * note that in the output dataframe, any feature which was already chosen,\n",
    "#            will be disregarded. In other words, such a case will result in less\n",
    "#            output features. For instance if we have 50 input features, and the sample\n",
    "#            ratio is 0.5, we should expect 25 sampled feature columns. But if one of the features\n",
    "#            was selected twice, we expect only 24 feature columns.\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_instances - a dataframe containing all feature vectors from the dataset.\n",
    "# - sampleRatio - the ratio of the sampeling out of feature set,\n",
    "#               * we will derive the number of features from sampleRatio\n",
    "# ------------\n",
    "# return value:\n",
    "# - X_instances_featureSampled - a dataframe containing feature vectors with sampled features. \n",
    "#                               * note the instances refer to the same instances as the input dataframe.\n",
    "#                               * the difference is in the columns (the selected features). \n",
    "# --------------------- \n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------- \n",
    "def featureBootStrap(X_instances, sampleRatio):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a18ff7bc2687c3f25c57d2490e25983",
     "grade": true,
     "grade_id": "feature-bootstrap-test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 4\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'featureBootStrap' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------------------------------------------\n",
    "print (\"Testing your implementation of the 'featureBootStrap' method ...\")\n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "\n",
    "columns = X_vectors.columns\n",
    "columns_50 = columns[:50] \n",
    "X_vectors_columns_50 = X_vectors[columns_50]\n",
    "sampleRatio = 0.5\n",
    "X_Sampled = featureBootStrap(X_vectors_columns_50, sampleRatio)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "assert X_Sampled is not None, 'X_Sampled object not initialized'\n",
    "assert isinstance(X_Sampled, pd.DataFrame), 'X_Sampled object is not a dataframe'\n",
    "assert X_Sampled.empty == False, 'X_Sampled dataframe object is empty'\n",
    "assert X_Sampled.shape[1] >10, 'X_Sampled dataframe object has a wrong number of sampled features'\n",
    "\n",
    "print (\"\\n----> The 'featureBootStrap' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "columns = None\n",
    "columns_50 = None\n",
    "X_vectors_columns_50 = None\n",
    "sampleRatio = None\n",
    "X_Sampled = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3b - Building a model  - maximum possible points: 4\n",
    "The following cells perform the following:\n",
    "* step 1 - decision stumps (and other classification utilities) ----> run only\n",
    "* step 2 - Bagging (fit)  ----> Student's implementation - total 4 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3b - step 1 - decision stumps (and other classification utilities) ----> run only\n",
    "<img src=\"./images/treeStumps.jpg\" alt=\"bagging-classifier\" width=\"400\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0dae4c037b73f2eb3b660ab30ac616d8",
     "grade": false,
     "grade_id": "decision-stump-train",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# class 1: DecisionStump\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- wraps an api for decision stumps, so we have a unified api\n",
    "# ------------\n",
    "class DecisionStump():\n",
    "    def __init__(self):\n",
    "        self._decisionStump = DecisionTreeClassifier(max_depth=1)\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        self._decisionStump.fit(X_train,y_train)\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        return self._decisionStump.predict(X_test)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# class2: ClassiferInstGen\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- utility classifier to generate objects of the classification algorithm class   \n",
    "# ------------\n",
    "class ClassiferInstGen():\n",
    "    def __init__(self,classifierPyClass):\n",
    "        self._classifierPyClass = classifierPyClass\n",
    "        \n",
    "    def getNewClassifierPyObj(self):\n",
    "        return self._classifierPyClass()\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# class3: BootstrapFeatureClassifer\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- container classifier to save model and bootstrap features    \n",
    "# ------------\n",
    "class BootstrapFeatureClassifer():\n",
    "    def __init__(self,trainModel,featureNames):\n",
    "        self.model = trainModel\n",
    "        self.featureNames = featureNames\n",
    "\n",
    "        \n",
    "# --------------------------------------------------------\n",
    "# method name1: trainBootstrapedClassificationModel\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- trains a classification model which matches the sklearn API of fit and predict.\n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_sampled_train -  a dataframe containing all feature vectors of the train set\n",
    "# - y_train - a series of containing all class values per train instance\n",
    "# Note: the X_sampled_train, y_train parameters could be instance bootsraped, feature bootsraped, both or none\n",
    "# - classificationAlgo_pyClass - the python 'class' parameter of a classification algorithm \n",
    "#                                For instance, the above 'DecisionStump' class.\n",
    "#                                Note: passing the pyton class is similar to passing a method\n",
    "#                                      as a parameter. Each call to: classificationAlgo_pyClass()\n",
    "#                                      creates a new object (also called instance of the class)\n",
    "#                                      of the type of the class.  \n",
    "# ------------\n",
    "# return value:\n",
    "# - featuresTrainModelObj - an object including trained model and feature names \n",
    "# --------------------- \n",
    "def trainBootstrapedClassificationModel(X_sampled_train, y_train,classificationAlgo_pyClass):\n",
    "    classiferInstGen = ClassiferInstGen(classificationAlgo_pyClass)\n",
    "    classificationObj = classiferInstGen.getNewClassifierPyObj()\n",
    "    classificationObj.fit(X_sampled_train, y_train)\n",
    "    featuresTrainModelObj = BootstrapFeatureClassifer(classificationObj,X_sampled_train.columns)\n",
    "    return featuresTrainModelObj\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name2: classifierPredict\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- predict test examples using a classification model (which corresponds to sklearn classifier APIs)\n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_test -  a dataframe containing feature vectors of the test set\n",
    "# - classification_obj - trained classificaion model (which corresponds to sklearn classifier APIs)\n",
    "# ------------\n",
    "# return value:\n",
    "# - yHat - a series of the predictions for each test instance  \n",
    "# --------------------- trainBootstrapedFeatureModel(X_sampled_train, y_train,classificationAlgo_pyClass)\n",
    "def classifierPredict(X_test, featuresTrainModelObj):\n",
    "    X_adapted = X_test[featuresTrainModelObj.featureNames]\n",
    "    predictions = featuresTrainModelObj.model.predict(X_adapted)\n",
    "    yHat = pd.Series(data=predictions,index=X_test.index)\n",
    "    return yHat\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 11)\n",
    "X_train_1st_k = X_train.iloc[:1000,:] \n",
    "y_train_1st_k = y_train.iloc[:1000]\n",
    "X_train_2nd_k = X_train.iloc[1000:2000,:] \n",
    "y_train_2nd_k = y_train.iloc[1000:2000]\n",
    "classificationModel1=trainBootstrapedClassificationModel(X_train_1st_k, y_train_1st_k,DecisionStump)\n",
    "classificationModel2=trainBootstrapedClassificationModel(X_train_2nd_k, y_train_2nd_k,DecisionStump)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# show usages of functions\n",
    "# --------------------------------------------------------\n",
    "print ('A few prediction examples:')\n",
    "nExamples=5\n",
    "\n",
    "y_hat1 = classifierPredict(X_test.iloc[:nExamples,:], classificationModel1)\n",
    "y_hat2 = classifierPredict(X_test.iloc[:nExamples,:], classificationModel2)\n",
    "for nInd in range(nExamples):\n",
    "    print ('test instance [%d]: actual: %r, prediction(classifier1): %r, prediction(classifier2): %r' %(nInd,y_test.iloc[nInd],y_hat1.iloc[nInd],y_hat2.iloc[nInd]))\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat1 = None\n",
    "y_hat2 = None\n",
    "X_train_1st_k = None \n",
    "y_train_1st_k = None\n",
    "X_train_2nd_k = None \n",
    "y_train_2nd_k = None\n",
    "classificationModel1=None\n",
    "classificationModel2=None\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3b - step 2 - Bagging (fit)  ----> Student's implementation - total 4 points\n",
    "<img src=\"./images/bags.jpg\" alt=\"The bagging operation\" width=\"200\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ae5e1282bfd518ff737e46ecda8e11e",
     "grade": false,
     "grade_id": "bagging-fit",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 4\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: baggingFit\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return the a list of models created after bootstraping instances & features.\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_train - a dataframe containing all feature vectors of the train set\n",
    "# - y_train - a series of containing all class values per train instance\n",
    "# - instanceSampleRatio - the ratio of the sampeling out of training set, \n",
    "#                        * we will pass it on as a parameter, in order to sample instances.\n",
    "#                        - if instanceSampleRatio<=0, no instance bootstrap is done, and we leave\n",
    "#                          the training instances with no change.\n",
    "# - featureSampleRatio - the ratio of the sampeling out of feature set,\n",
    "#                        * we will pass it on as a parameter, in order to sample features.\n",
    "#                        - if featureSampleRatio<=0, no feature bootstrap is done, and we leave\n",
    "#                          the features with no change.\n",
    "# - classificationAlgo_pyClass - the python 'class' parameter of a classification algorithm \n",
    "#                                For instance, the above 'DecisionStump' class.\n",
    "#                                Note: passing the pyton class is similar to passing a method\n",
    "#                                      as a parameter.    \n",
    "# - numModels - number of models to train in bagging\n",
    "# Note: the X_train, y_train parameters could be instance bootsraped, feature bootsraped or both\n",
    "# ------------\n",
    "# return value:\n",
    "# - a list of trained models \n",
    "#  notes:\n",
    "#        * the number of models are detrminded by the input parameter \n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "def baggingFit(X_train, y_train, instanceSampleRatio, featureSampleRatio, classificationAlgo_pyClass, numModels):\n",
    "    # note that FOR EACH bootstraped train set and/or feature set you need to create a classifier using:\n",
    "    # classificationModel=trainBootstrapedClassificationModel(X_train_bootstraped, y_train_corrolated_labels,classificationAlgo_pyClass)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86ecc8568c150ec0909a409c70b4d08b",
     "grade": true,
     "grade_id": "cell-fcf5b9299c2d8e0a",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 4\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'baggingFit' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "print (\"Testing your implementation of the 'baggingFit' method ...\")\n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 25)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "innerElementTupple = lambda arrValues: False not in (isinstance(elem,tuple) for elem in arrValues)\n",
    "# --------------------------------------------------------\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels = 3\n",
    "classification_PyClass = DecisionStump\n",
    "baggedModels =  baggingFit(X_train, y_train, instanceSampleRatio, featureSampleRatio, classification_PyClass, numModels)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "print (\"check basic 'baggingFit' output validation ...\")\n",
    "assert baggedModels is not None, 'baggedModels object not initialized'\n",
    "assert isinstance(baggedModels, list), 'baggedModels object is not a list'\n",
    "assert None not in baggedModels, 'baggedModels should not include None elements'\n",
    "assert False not in [isinstance(elem,BootstrapFeatureClassifer) for elem in baggedModels], 'baggedModels should include only DecisionStump objects'\n",
    "\n",
    "print ('trying to create inner bagged models prediction ...')\n",
    "nExamples=20\n",
    "y_hat_arr = [classifierPredict(X_test.iloc[:nExamples],model) for model in baggedModels]\n",
    "assert False not in [allValidVals(y_hat.values,(0,1)) for y_hat in y_hat_arr], 'something went wrong with bagging inner models - invalid values found (valid values: 0 or 1)'\n",
    "\n",
    "print (\"----> The 'baggingFit' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "\n",
    "print ('\\n----------------------')\n",
    "print ('A few prediction examples:')\n",
    "for nInd in range(nExamples):\n",
    "    predictions = '; '.join('[bag-model %d]: %r' %(nPred,y_hat_arr[nPred].iloc[nInd]) for nPred in range(len(y_hat_arr)))\n",
    "    print ('test instance [%d]: actual: %r, predictions: %r' %(nInd,y_test.iloc[nInd],predictions))\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "y_hat_arr = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 - Prediction -  maximum possible points: 3\n",
    "The following cells perform the following:\n",
    "* step 1 - predict (voting)    ----> Student's implementation - total 3 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2731d5d8644eff28931755a6472cb658",
     "grade": false,
     "grade_id": "bagging-predict",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 2\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: baggingPredict\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return the predicted value for each test instances, \n",
    "#     based on the bagged trained models \n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_test -  a dataframe containing feature vectors of the test set\n",
    "# - baggingModels - the list of bagged models returned from 'baggingFit'\n",
    "# ------------\n",
    "# return value:\n",
    "# - y_hat - a series of the prediction, with the same index as X_test \n",
    "#  notes:\n",
    "#        * the number of models are detrminded by the input parameter \n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "def baggingPredict(X_test, baggingModels):\n",
    "    # note that FOR EACH model in baggingModels, predict the value using:\n",
    "    # y_test=classifierPredict(X_test, baggingModel)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eacc32a46056c90bd031c2b2e6414d82",
     "grade": true,
     "grade_id": "bagging-predict-test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL (PART 1)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 3\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'baggingPredict' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 25)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "innerElementTupple = lambda arrValues: False not in (isinstance(elem,tuple) for elem in arrValues)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "print (\"check basic 'baggingPredict' output validation (part 1) ...\")\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels = 10\n",
    "classification_PyClass = DecisionStump\n",
    "baggedModels =  baggingFit(X_train, y_train, instanceSampleRatio, featureSampleRatio, classification_PyClass, numModels)\n",
    "yHat = baggingPredict(X_test, baggedModels)\n",
    "assert yHat is not None, 'yHat object not initialized'\n",
    "assert isinstance(yHat, pd.Series), 'yHat object is not a pandas series'\n",
    "assert None not in yHat.values, 'yHat should not include None elements'\n",
    "\n",
    "print (\"----> The 'baggingPredict' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "# --------------------------------------------------------\n",
    "print (\"check basic 'baggingPredict' output validation (part 2) ...\")\n",
    "assert allValidVals(yHat.values,(0,1)), 'prediction err - something went wrong with bagging inner models - invalid values found (valid values: 0 or 1)'\n",
    "\n",
    "print (\"----> The 'baggingPredict' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "\n",
    "print ('\\n----------------------')\n",
    "print ('A few prediction examples:')\n",
    "nExamples = 20\n",
    "for nInd in range(nExamples):\n",
    "    print ('test instance [%d]: actual: %r, predictions: %r' %(nInd,y_test.iloc[nInd],yHat.iloc[nInd]))\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat = None\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "y_hat_arr = None\n",
    "# --------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 - Evaluation - maximum possible points: 2\n",
    "The following cells perform the following:\n",
    "* step 1 - evaluate confusion matrix ----> run only\n",
    "* step 2 - evaluate precision  ----> Student's implementation - total 1 points\n",
    "* step 3 - evaluate recall     ----> Student's implementation - total 1 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 5 - step 1 - evaluate confusion matrix ----> run only\n",
    "<img src=\"./images/confusion_matrix.jpg\" alt=\"confusion_matrix\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf2aeaf3bcec6acf67ed2a7207d24a8b",
     "grade": false,
     "grade_id": "confusion-matrix",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# methos: getConfusionMatrix\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- compute the 4 values of the confusion matrix: TN, FP, FN, TP\n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - y_hat -  a series of containing all predicted class values per test instance\n",
    "# - y_test - a series of containing all class values per test instance\n",
    "# ------------\n",
    "# return values (comma seperated):\n",
    "# - TN - True negatives - number of instances, for which the actual value (from y_test) \n",
    "#                         is 0 (negative class, not_spam in our dataset) and \n",
    "#                         the predicted value (from y_hat) is also 0.\n",
    "# - FP - True negatives - number of instances, for which the actual value (from y_test) is 0, but \n",
    "#                         the predicted value (from y_hat) is 1 (positive class, spam in our dataset).\n",
    "# - FN - False negatives - number of instances, for which the actual value (from y_test) is 1, but                          \n",
    "#                         the predicted value (from y_hat) is 0.\n",
    "# - TP - False negatives - number of instances, for which the actual value (from y_test) is 1 and                          \n",
    "#                         the predicted value (from y_hat) is also 1.\n",
    "# --------------------- \n",
    "def getConfusionMatrix(y_hat,y_test):\n",
    "    TN = len([1 for ind in range(len(y_test)) if y_test.iloc[ind]==0 and y_hat.iloc[ind]==0])\n",
    "    FP = len([1 for ind in range(len(y_test)) if y_test.iloc[ind]==0 and y_hat.iloc[ind]==1])\n",
    "    FN = len([1 for ind in range(len(y_test)) if y_test.iloc[ind]==1 and y_hat.iloc[ind]==0])\n",
    "    TP = len([1 for ind in range(len(y_test)) if y_test.iloc[ind]==1 and y_hat.iloc[ind]==1])\n",
    "    return TN,FP,FN,TP\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 11)\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels = 10\n",
    "classification_PyClass = DecisionStump\n",
    "baggedModels =  baggingFit(X_train, y_train, instanceSampleRatio, featureSampleRatio, classification_PyClass, numModels)\n",
    "y_hat = baggingPredict(X_test, baggedModels)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "numTN,numFP,numFN,numTP = getConfusionMatrix(y_hat,y_test)\n",
    "print ('confusion matrix:')\n",
    "print ('\\tpred-0\\tpred-1')\n",
    "print ('is-0\\tTN=%d\\tFP=%d' %(numTN,numFP))\n",
    "print ('is-1\\tFN=%d\\tTP=%d' %(numFN,numTP))\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 5 - step 2 - evaluate precision  ----> Student's implementation - total 1 points\n",
    "<img src=\"./images/confusion_matrix-precision-recall.jpg\" alt=\"confusion_matrix-precision-recall\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b69474bfc34b04f54ed4ba3231fe6ca",
     "grade": false,
     "grade_id": "precision",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 5\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: getPrecision\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return the precision for class 1 (spam in out dataset)\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - y_hat -  a series of containing all predicted class values per test instance\n",
    "# - y_test - a series of containing all class values per test instance\n",
    "# ------------\n",
    "# return value:\n",
    "# - precision value\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "\n",
    "def getPrecision(y_hat,y_test):\n",
    "    # note that you could use getConfusionMatrix(y_hat,y_test) to make it simpler\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7711af4832957f7db47679264b406596",
     "grade": true,
     "grade_id": "precision-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'getPrecision' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 25)\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels = 5\n",
    "classification_PyClass = DecisionStump\n",
    "baggedModels =  baggingFit(X_train, y_train, instanceSampleRatio, featureSampleRatio, classification_PyClass, numModels)\n",
    "yHat = baggingPredict(X_test, baggedModels)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "innerElementTupple = lambda arrValues: False not in (isinstance(elem,tuple) for elem in arrValues)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "print (\"check basic 'getPrecision' output validation ...\")\n",
    "precision = getPrecision(yHat,y_test)\n",
    "assert precision is not None, 'precision not initialized'\n",
    "assert precision>0, 'precision should not be 0'\n",
    "assert precision<=1, 'precision should not be more than 1 (=100%)'\n",
    "assert precision>0.7, 'precision should not be >0.7 (more than 70%)'\n",
    "print ('pricision=%r' %(precision))\n",
    "print (\"----> The 'getPrecision' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "\n",
    "print ('\\n----------------------')\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat = None\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "y_hat_arr = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 5 - step 3 - evaluate recall     ----> Student's implementation - total 1 points\n",
    "<img src=\"./images/confusion_matrix-precision-recall.jpg\" alt=\"confusion_matrix-precision-recall\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61a534760b431f9a711978e63a08aee9",
     "grade": false,
     "grade_id": "recall",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 5\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: getRecall\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method needs to return the recall for class 1 (spam in out dataset)\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - y_hat -  a series of containing all predicted class values per test instance\n",
    "# - y_test - a series of containing all class values per test instance\n",
    "# ------------\n",
    "# return value:\n",
    "# - recall value\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "\n",
    "def getRecall(y_hat,y_test):\n",
    "    # note that you could use getConfusionMatrix(y_hat,y_test) to make it simpler\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a49bb5f249f097904727a5243c46e74",
     "grade": true,
     "grade_id": "recall-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 1\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'getRecall' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 25)\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels = 10\n",
    "classification_PyClass = DecisionStump\n",
    "baggedModels =  baggingFit(X_train, y_train, instanceSampleRatio, featureSampleRatio, classification_PyClass, numModels)\n",
    "yHat = baggingPredict(X_test, baggedModels)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "innerElementTupple = lambda arrValues: False not in (isinstance(elem,tuple) for elem in arrValues)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "print (\"check basic 'getRecall' output validation ...\")\n",
    "recall = getRecall(yHat,y_test)\n",
    "assert recall is not None, 'precision not initialized'\n",
    "assert recall>0, 'recall should not be 0'\n",
    "assert recall<=1, 'recall should not be more than 1 (=100%)'\n",
    "assert recall>0.3, 'recall should not be >0.5 (more than 50%)'\n",
    "print ('recall=%r' %(recall))\n",
    "print (\"----> The 'getRecall' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "\n",
    "print ('\\n----------------------')\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat = None\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "y_hat_arr = None\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6 - Bonus Question - maximum possible points: 5\n",
    "The following cells perform the following:\n",
    "* step 1 - evaluate accuracy ----> run only\n",
    "* step 2 - split the data-set to train-set, validation-set and test-set ----> run only\n",
    "* step 3 - bagging hyperparameters tuning ----> Student's implementation - total 5 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 6 - step 1 - evaluate accuracy   ----> run only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c58069385536de5ade9b7c83b03d0456",
     "grade": false,
     "grade_id": "accuracy",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# methos: getConfusionMatrix\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- computes the accuracy of the classifier\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - y_hat -  a series of containing all predicted class values per test instance\n",
    "# - y_test - a series of containing all class values per test instance\n",
    "# ------------\n",
    "# return value:\n",
    "# - accuracy value\n",
    "# --------------------- \n",
    "def getAccuracy(y_hat,y_test):\n",
    "    correct = float(len([1 for ind in range(len(y_test)) if y_test.iloc[ind]==y_hat.iloc[ind]]))\n",
    "    return correct/float(len(y_test))\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_test, y_train, y_test = trainTestSplit(X_vectors, y_categories, 0.2, 11)\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels = 5\n",
    "classification_PyClass = DecisionStump\n",
    "baggedModels =  baggingFit(X_train, y_train, instanceSampleRatio, featureSampleRatio, classification_PyClass, numModels)\n",
    "y_hat = baggingPredict(X_test, baggedModels)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "accuracy = getAccuracy(y_hat,y_test)\n",
    "print ('accuracy: %r' %(accuracy))\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 6 - step 2 - split the data-set to train-set, validation-set and test-set ----> run only\n",
    "<img src=\"./images/train-validation-test-split.png\" alt=\"train-validation-test split\" width=\"300\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62be65e60243b0bd9827fb0437841beb",
     "grade": false,
     "grade_id": "train-validation-test-split",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# NO IMPLEMENTAION - DO NO CHANGE\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name1: trainValidationTestSplit\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# What does the method do?\n",
    "# --- the method split the input dataset into train and test. \n",
    "#     - It does so using the sklearn built in method\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_vectors - a dataframe containing all feature vectors. \n",
    "# - y_categories - a series of containing all class values per instance.\n",
    "# - test_size_ratio - a number (0<number<1) of the wanted ratio of the dataset out of the dataset \n",
    "# - rand_state - a number, in order to guarantee reproducible results \n",
    "# ------------\n",
    "# return values (comma separated):\n",
    "# - X_train -  a dataframe containing all feature vectors of the train set\n",
    "# - X_test -  a dataframe containing all feature vectors of the test set\n",
    "# - y_train - a series of containing all class values per train instance\n",
    "# - y_test - a series of containing all class values per test instance\n",
    "# --------------------- \n",
    "def trainValidationTestSplit(X_vectors, y_categories, validation_or_test_size_ratio, rand_state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_vectors, y_categories, test_size=validation_or_test_size_ratio, random_state=rand_state)\n",
    "    validationRatio = validation_or_test_size_ratio / (1-validation_or_test_size_ratio)\n",
    "    X_train, X_validation, y_train, y_validation =  train_test_split(X_train, y_train, test_size=validationRatio, random_state=rand_state)\n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test  \n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test =  trainValidationTestSplit(X_vectors, y_categories, 0.2, 43)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# display train-test split information\n",
    "# --------------------------------------------------------\n",
    "print ('Information after train-test split:')\n",
    "print('* The train-set includes %d instances and %d corresponding categories' %(X_train.shape[0],y_train.shape[0]))\n",
    "print('* The validation-set includes %d instances and %d corresponding categories' %(X_validation.shape[0],y_validation.shape[0]))\n",
    "print('* The test-set includes %d instances and %d corresponding categories' %(X_test.shape[0],y_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 6 - step 3 - bagging hyperparameters tuning (using grid search) ----> Student's implementation - total 5 points\n",
    "<img src=\"./images/grid_search.png\" alt=\"train-validation-test split\" width=\"100\" align='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Add assistance code here IF NEEDED:\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6398c5857a174c6b4cb5b14abb8f01c5",
     "grade": false,
     "grade_id": "hyperparametes-tune",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# IMPLEMENTATION CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 5\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# method name: baggingFit\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# The following is expected:\n",
    "# --- the method chooses the best permutation of bagging model hyperparameters, using grid search\n",
    "# ------------\n",
    "# input parameters:\n",
    "# - X_train - a dataframe containing all feature vectors of the train set\n",
    "# - y_train - a series of containing all class values per train instance\n",
    "# - instanceSampleRatio - the ratio of the sampeling out of training set, \n",
    "#                        * we will pass it on as a parameter, in order to sample instances.\n",
    "#                        - if instanceSampleRatio<=0, no instance bootstrap is done, and we leave\n",
    "#                          the training instances with no change.\n",
    "# - featureSampleRatio - the ratio of the sampeling out of feature set,\n",
    "#                        * we will pass it on as a parameter, in order to sample features.\n",
    "#                        - if featureSampleRatio<=0, no feature bootstrap is done, and we leave\n",
    "#                          the features with no change.\n",
    "# - classificationAlgo_pyClass_Arr - an array of the python 'class' parameters of a classification algorithm to choose from,\n",
    "#                                For instance, the above [DecisionStump, NaiveBayes].\n",
    "#                                Note: passing the pyton class is similar to passing a method\n",
    "#                                      as a parameter.    \n",
    "# - numModels_Arr - an array of the options of the number of bagging models to train, for which we need to choose from\n",
    "#                   For instance: [3,5,10]\n",
    "# Note: the X_train, y_train parameters could be instance bootsraped, feature bootsraped or both\n",
    "# ------------\n",
    "# return values (comma seperated):\n",
    "# - allBaggedModels - an array of all trainedBaggedModels,\n",
    "# - best_baggedModels - array of the baggedModels ensembles (from baggeningFit), reaching the highest accuracy\n",
    "# - bestAccuracy - the highest accuracy (number) of all baggedModels ensemble\n",
    "# - best_classificationAlgo_pyClass - the classificationAlgo_pyClass (e.g. DecisionStump) of\n",
    "#                                     baggedModels ensemble with highest accuracy\n",
    "# - best_numModels - the num of 'bagged' Models (e.g. 5) of\n",
    "#                    baggedModels ensemble with highest accuracy\n",
    "# ---------------------\n",
    "# --- General notes:\n",
    "# Don't forget to remove the 'raise NotImplementedError()' line.\n",
    "# In the line following the '# YOUR CODE HERE' line, add your code\n",
    "# ---------------------\n",
    "# --- Additional notes:\n",
    "# - You must use the parameters you've got. \n",
    "# - Do NOT define the parameters in the method.\n",
    "# --------------------------------------------------------\n",
    "def gridSearchBaggingModel(X_train, y_train, X_validation, y_validation, instanceSampleRatio, featureSampleRatio, classificationAlgo_pyClass_Arr, numModels_Arr):\n",
    "    # hint: for each permutation, use assistance functions:\n",
    "    #       - baggingFit, baggingPredict, getAccuracy \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# - add your tests here IF NEEDED:\n",
    "# Note: any additional tests are for your use only.\n",
    "# Note: We depend only on tests we wrote.\n",
    "# ------\n",
    "\n",
    "\n",
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9dc255e185a039c097690ba2b38d2529",
     "grade": true,
     "grade_id": "hyperparametes-tune-test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# TEST ONLY CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# YOU MUST RUN THIS NOTEBOOK CELL\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Important Notes:\n",
    "# - This test cell MUST NOT raise any exception\n",
    "# - It must pass all tests to get the point ----- #\n",
    "# - Do NOT change or delete this cell\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Grading - Maximum points: 5\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Test of:\n",
    "### --- Graded tests for the 'getRecall' method \n",
    "# Important Note: additional test might also be taken from our side.\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Temporary imports:\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# --------\n",
    "folderName = '.' + os.sep + 'data' \n",
    "datasetCsvFileName = folderName + os.sep + 'spam_notSpam.csv'\n",
    "# --------------------- \n",
    "dataset_forTesting = loadDataset(datasetCsvFileName)\n",
    "X_vectors, y_categories = separateTo_X_and_y(dataset_forTesting, 'class')\n",
    "y_categories = datasetCategoriesToNums(y_categories, 'spam')\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test =  trainValidationTestSplit(X_vectors, y_categories, 0.2, 19)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "allValidVals = lambda arrValues,validVals: False not in (val in validVals for val in arrValues) \n",
    "sameIndexes = lambda obj1,obj2: False not in (obj1.index.tolist()[n] == obj2.index.tolist()[n] for n in range(len(obj1.index))) \n",
    "innerElementTupple = lambda arrValues: False not in (isinstance(elem,tuple) for elem in arrValues)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "instanceSampleRatio = 0.1\n",
    "featureSampleRatio = 0.5\n",
    "numModels_Arr = [5,10,40]\n",
    "classificationAlgo_pyClass_Arr = [DecisionStump,GaussianNB]\n",
    "allBaggedModels,best_baggedModels,bestAccuracy, best_classificationAlgo_pyClass,best_numOfModels = gridSearchBaggingModel(\n",
    "                        X_train, y_train, X_validation, y_validation, instanceSampleRatio, featureSampleRatio, \n",
    "                                                         classificationAlgo_pyClass_Arr, numModels_Arr)\n",
    "\n",
    "print (\"check basic 'gridSearchBaggingModel' output validation ...\")\n",
    "assert allBaggedModels is not None, 'allBaggedModels not initialized'\n",
    "assert best_baggedModels is not None, 'best_baggedModels not initialized'\n",
    "assert bestAccuracy is not None, 'bestAccuracy not initialized'\n",
    "assert best_classificationAlgo_pyClass is not None, 'best_classificationAlgo_pyClass not initialized'\n",
    "assert best_numOfModels is not None, 'best_numOfModels not initialized'\n",
    "assert isinstance(allBaggedModels, list), 'allBaggedModels object is not a list'\n",
    "assert isinstance(best_baggedModels, list), 'best_baggedModels object is not a list'\n",
    "assert bestAccuracy>0, 'bestAccuracy should not be 0'\n",
    "assert bestAccuracy<=1, 'bestAccuracy should not be more than 1 (=100%)'\n",
    "assert bestAccuracy>0.6, 'bestAccuracy should not be >0.6 (more than 60%)'\n",
    "assert None not in allBaggedModels, 'allBaggedModels should not include None elements'\n",
    "assert None not in best_baggedModels, 'best_baggedModels should not include None elements'\n",
    "\n",
    "print (\"----> The 'gridSearchBaggingModel' test passed successfully :-) \\n\")\n",
    "print ('\\nAdditional Tests might be executed on our side')\n",
    "\n",
    "print ('\\n----------------------')\n",
    "print ('Best bagged Classification algo: %r, num of models: %r, accuracy: %r' %(best_classificationAlgo_pyClass.__name__,best_numOfModels,bestAccuracy))\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "if 'DecisionTreeClassifier' in sys.modules:\n",
    "    del (DecisionTreeClassifier)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------------\n",
    "dataset_forTesting = None\n",
    "X_vectors = None\n",
    "y_categories = None\n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_hat = None\n",
    "yHat = None\n",
    "\n",
    "instanceSampleRatio = None\n",
    "featureSampleRatio = None\n",
    "numModels = None\n",
    "classification_PyClass = None\n",
    "baggedModels = None\n",
    "\n",
    "nExamples = None\n",
    "y_hat_arr = None\n",
    "# --------------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
